{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "rEQEnqC0Lino",
        "outputId": "39baea0a-de01-4a04-8819-c79601707cf2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6389b4dbada5>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Make predictions on the testing dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mtest_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Evaluate the model's performance on the testing dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m         \"\"\"\n\u001b[0;32m--> 820\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0mcorresponds\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m         \"\"\"\n\u001b[0;32m--> 860\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the testing dataset\n",
        "test_df = pd.read_csv(\"https://raw.githubusercontent.com/andvise/DataAnalyticsDatasets/main/test_dataset.csv\", index_col=0)\n",
        "\n",
        "# Preprocess the testing dataset\n",
        "test_features = test_df.drop(columns=['target'])\n",
        "test_labels = test_df['target']\n",
        "\n",
        "# There are 4 columns for weight entropy that are fully NaN values and non numeric, hence they will not aid our classifier and should be removed. \n",
        "non_numeric_columns = test_features.select_dtypes(include=['object']).columns\n",
        "test_features_numeric = test_features.drop(columns=non_numeric_columns)\n",
        "\n",
        "# Fill NaN values with 0\n",
        "test_features_numeric = test_features_numeric.fillna(0)\n",
        "\n",
        "# Replace infinite values with the maximum value possible in each feature column\n",
        "test_features_numeric = test_features_numeric.replace([np.inf, -np.inf], np.nan)\n",
        "test_features_numeric = test_features_numeric.fillna(test_features_numeric.max())\n",
        "\n",
        "# Create a Random Forest model\n",
        "random_forest = RandomForestClassifier(n_estimators=100, random_state=6405)\n",
        "\n",
        "# Make predictions on the testing dataset\n",
        "test_preds = random_forest.predict(test_features_numeric)\n",
        "\n",
        "# Evaluate the model's performance on the testing dataset\n",
        "test_accuracy = accuracy_score(test_labels, test_preds)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING THE RANDOM FOREST AND FITTING IT \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/andvise/DataAnalyticsDatasets/main/train_dataset.csv\", index_col=0)\n",
        "\n",
        "features = df.drop(columns=['target'])  \n",
        "labels = df['target']  \n",
        "\n",
        "# There are 4 columns for weight entropy that are fully NaN values and non numeric, hence they will not aid our classifier and should be removed. \n",
        "non_numeric_columns = features.select_dtypes(include=['object']).columns\n",
        "features_numeric = features.drop(columns=non_numeric_columns)\n",
        "\n",
        "# Filling all the NaNs left with 0s, next will deal with infinity values\n",
        "features_numeric = features_numeric.fillna(0)\n",
        "\n",
        "# Getting a few errors which require preproccesing, see below for details. \n",
        "# \"Input X contains infinity or a value too large for dtype('float64') - As a result replacing infinite values with the maximum value possible in each feature column. \n",
        "features_numeric = features_numeric.replace([np.inf, -np.inf], np.nan)\n",
        "features_numeric = features_numeric.fillna(features_numeric.max())\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features_numeric, labels, test_size=0.3, random_state=6405)\n",
        "\n",
        "# Create a Random Forest model\n",
        "random_forest = RandomForestClassifier(n_estimators=100, random_state=6405)\n",
        "\n",
        "# Train the model on the training data\n",
        "random_forest.fit(train_features, train_labels)\n",
        "\n",
        "# TESTING ON THE NEW TESTING SET\n",
        "\n",
        "# Load the testing dataset\n",
        "test_df = pd.read_csv(\"https://raw.githubusercontent.com/andvise/DataAnalyticsDatasets/main/test_dataset.csv\", index_col=0)\n",
        "\n",
        "# Preprocess the testing dataset\n",
        "test_features = test_df.drop(columns=['target'])\n",
        "test_labels = test_df['target']\n",
        "\n",
        "# There are 4 columns for weight entropy that are fully NaN values and non numeric, hence they will not aid our classifier and should be removed. \n",
        "non_numeric_columns = test_features.select_dtypes(include=['object']).columns\n",
        "test_features_numeric = test_features.drop(columns=non_numeric_columns)\n",
        "\n",
        "# Fill NaN values with 0\n",
        "test_features_numeric = test_features_numeric.fillna(0)\n",
        "\n",
        "# Replace infinite values with the maximum value possible in each feature column\n",
        "test_features_numeric = test_features_numeric.replace([np.inf, -np.inf], np.nan)\n",
        "test_features_numeric = test_features_numeric.fillna(test_features_numeric.max())\n",
        "\n",
        "# Make predictions on the testing dataset\n",
        "test_preds = random_forest.predict(test_features_numeric)\n",
        "\n",
        "# Evaluate the model's performance on the testing dataset\n",
        "test_accuracy = accuracy_score(test_labels, test_preds)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JK7msZrM4hV",
        "outputId": "2f889883-48ff-42aa-eb4f-e4d8852fc690"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 1.0\n"
          ]
        }
      ]
    }
  ]
}